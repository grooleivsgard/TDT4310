{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Chunking\n",
    "**1. Create a chunker that detects noun-phrases (NPs) and lists the NPs in the text below.**\n",
    "\n",
    "- Both [NLTK](https://www.nltk.org/book/ch07.html) and [spaCy](https://spacy.io/api/matcher) supports chunking\n",
    "- Look up RegEx parsing for NLTK and the document object for spaCy.\n",
    "- Make use of what you've learned about tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The language model',\n",
       " 'predicted',\n",
       " 'the next word',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a very nice word',\n",
       " '!']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"The language model predicted the next word. It was a very nice word!\"\n",
    "\n",
    "# load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# preprocess text (tokenization, POS tagging etc)\n",
    "doc = nlp(text)\n",
    "\n",
    "# initialize a list to keep track of noun phrase tokens\n",
    "noun_phrase_tokens = set()\n",
    "# dictionary to keep track of which tokens belong to which noun phrase\n",
    "noun_phrases_dict = {}\n",
    "\n",
    "# mark the tokens that are part of noun phrases\n",
    "for chunk in doc.noun_chunks:\n",
    "    np_text = chunk.text  # The text of the current noun phrase\n",
    "    for token in chunk:\n",
    "        noun_phrase_tokens.add(token.i)  # Add the token index to the set\n",
    "        noun_phrases_dict[token.i] = np_text  # Map token index to noun phrase text\n",
    "\n",
    "# initialize a list to store the final output\n",
    "output = []\n",
    "\n",
    "# iterate over each token in the document\n",
    "for token in doc:\n",
    "    if token.i in noun_phrase_tokens:\n",
    "        # If this token is part of a noun phrase and not already added, add the noun phrase\n",
    "        if noun_phrases_dict[token.i] not in output:\n",
    "            output.append(noun_phrases_dict[token.i])\n",
    "    else:\n",
    "        # If the token is not part of a noun phrase, add it as an individual token\n",
    "        output.append(token.text)\n",
    "\n",
    "\n",
    "# Output: a list of all tokens, grouped as noun-phrases where applicable\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Modify the chunker to handle verb-phases (VPs) as well.**\n",
    "- This can be done by using a RegEx parser in NLTK or using a spaCy Matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The language model', 'predicted', 'the next word', '.', 'It', 'was', 'a very nice word', '!']\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# using spaCy matcher for verb phrases\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# example pattern for verb phrases (an adverb followed by a verb) \n",
    "vp_pattern = [{\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"VERB\", \"OP\": \"+\"}]\n",
    "matcher.add(\"VP\", [vp_pattern])\n",
    "\n",
    "# initialize a list to keep track of phrase tokens and types\n",
    "phrase_tokens = set()\n",
    "\n",
    "# dictionary to keep track of which tokens belong to which phrase\n",
    "phrases_dict = {}\n",
    "\n",
    "# noun phrases\n",
    "for chunk in doc.noun_chunks:\n",
    "    np_text = chunk.text \n",
    "    for token in chunk:\n",
    "        phrase_tokens.add(token.i)\n",
    "        phrases_dict[token.i] = (np_text, \"NP\")\n",
    "\n",
    "# verb phrases\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    vp_text = doc[start:end].text\n",
    "    for token in doc[start:end]:\n",
    "        phrase_tokens.add(token.i)\n",
    "        phrases_dict[token.i] = (vp_text, \"VP\")\n",
    "\n",
    "# initialize a list to store the final output\n",
    "output = []\n",
    "\n",
    "# iterate over each token in the document\n",
    "for token in doc:\n",
    "    if token.i in phrase_tokens:\n",
    "        phrase_text, phrase_type = phrases_dict[token.i]\n",
    "        # add the phrase if it's not already in the output, checking for phrase type\n",
    "        if phrase_text not in output:\n",
    "            output.append(phrase_text)\n",
    "    else:\n",
    "        #if the token is not part of a phrase, add it as an individual token\n",
    "        output.append(token.text)\n",
    "\n",
    "# output: a list of all tokens, grouped as phrases if relevant\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Verb-phrases (VPs) can be defined by many different grammatical rules. Give four examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. VP -> V (simple verb phrase, e.g. \"run\")\n",
    "\n",
    "2. VP -> V NP (verb with direct object, e.g. \"saw the bird\")\n",
    "\n",
    "3. VP -> V NP NP (verb with direct object and indirect object, e.g. \"gave her a hug\")\n",
    "\n",
    "4. VP -> V PP (verb with a prepositional phrase, e.g. \"walked to the park\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. After these applications, do you find chunking to be beneficial in the context of language modeling and next-word prediction? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using chunking to identify nouns and verb phrases can help language models predict words, but requires accurate phrase identification which can be problematic. Incorrectly identified phrases due to ambiguous syntax or errors in part-of-speech tagging can mislead the model, leading to inaccurate predictions. The complexity of natural language means that there are many exceptions to syntactic rules, making it challenging to devise chunking rules that are both comprehensive and accurate across different contexts and text types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use spaCy to inspect/visualise the dependency tree of the text provided below.**\n",
    "- Optional addition: visualize the dependencies as a graph using `networkx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"37de3e66f4c344a78275584365ff138e-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">model</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">predicted</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">next</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">word</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37de3e66f4c344a78275584365ff138e-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37de3e66f4c344a78275584365ff138e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"The language model predicted the next word\"\n",
    "\n",
    "# load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# preprocess the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# visualize the dependency tree\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the root of the sentence? Attempt to spot it yourself, but the answer should be done by code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: predicted, POS tag: VERB\n"
     ]
    }
   ],
   "source": [
    "# find the root\n",
    "sentence_root = [token for token in doc if token.head == token][0]\n",
    "\n",
    "# print word and POS tag\n",
    "print(f\"Root: {sentence_root.text}, POS tag: {sentence_root.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the subject and object of a sentence. Print the results for the sentence above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: ['model']\n",
      "Objects: ['word']\n"
     ]
    }
   ],
   "source": [
    "def find_subjects_objects(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    subjects = []\n",
    "    objects = []\n",
    "    \n",
    "    # iterate over the tokens in the document\n",
    "    for token in doc:\n",
    "        # if the token is a subject, add it to the subjects list\n",
    "        if \"subj\" in token.dep_:\n",
    "            subjects.append((token.text))\n",
    "        # if the token is an object, add it to the objects list\n",
    "        elif \"obj\" in token.dep_:\n",
    "            objects.append((token.text))\n",
    "    \n",
    "    return subjects, objects\n",
    "\n",
    "subjects, objects = find_subjects_objects(text)\n",
    "\n",
    "print(\"Subjects:\", subjects)\n",
    "print(\"Objects:\", objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. How would you use the relationships extracted from dependency parsing in language modeling contexts?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependency parsing helps in understanding how different parts of a sentence are connected to each other and the roles they play in the sentence, allowing for a deeper understanding of the text. By integrating relationships extracted from dependency parsing into language modeling, the model's accuracy can be improved on both grammar, semantics, and syntactic understanding. This can be applied to enhance word predictions and generate texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use Wordnet (from NLTK) and create a function to get all synonyms of a word of your choice. Try with \"language\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms of \"course\": ['feed', 'naturally', 'course', 'trend', 'flow', 'class', 'grade', 'of_course', 'form', 'course_of_study', 'row', 'line', 'course_of_action', 'track', 'course_of_instruction', 'run', 'path']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def find_synonyms(word):\n",
    "    \n",
    "    # find synsets of the word\n",
    "    synsets = wn.synsets(word)\n",
    "    \n",
    "    # extract the lemma names (synonyms) from each synset\n",
    "    synonyms = set()\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    \n",
    "    return list(synonyms)\n",
    "\n",
    "word = \"course\"\n",
    "\n",
    "print(f'Synonyms of \"{word}\": {find_synonyms(word)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. From the same word you chose, extract an additional 4 or more features from wordnet (such as hyponyms). Describe each category briefly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyponyms: [Synset('adult_education.n.01'), Synset('art_class.n.01'), Synset('childbirth-preparation_class.n.01'), Synset('correspondence_course.n.01'), Synset('course_of_lectures.n.01'), Synset('directed_study.n.01'), Synset('elective_course.n.01'), Synset('extension_course.n.01'), Synset('home_study.n.01'), Synset('industrial_arts.n.01'), Synset('orientation_course.n.01'), Synset('propaedeutic.n.01'), Synset('refresher_course.n.01'), Synset('required_course.n.01'), Synset('seminar.n.02'), Synset('shop_class.n.01'), Synset('workshop.n.02')]\n",
      "Hypernyms: [Synset('education.n.01')]\n",
      "Meronyms: [Synset('course_session.n.01'), Synset('coursework.n.01'), Synset('lecture.n.03'), Synset('lesson.n.01')]\n",
      "Holonyms: []\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# format the output\n",
    "def format_synsets(synsets):\n",
    "    return [f\"{synset.lemmas()[0].name()}\" for synset in synsets]\n",
    "\n",
    "# Hyponyms: words that are a subclass of the concept represented by the synset, e.g. \"eagle\" given the concept \"bird\"\n",
    "hyponyms = wn.synsets(word)[0].hyponyms()\n",
    "\n",
    "# Hypernyms: opposite of hyponyms - a general concept a subclass belongs to, e.g. \"bird\" given the subclass \"eagle\"\n",
    "hypernyms = wn.synsets(word)[0].hypernyms()\n",
    "\n",
    "# Meronums: a part of / a member of the concept represented by the synset, e.g. \"leaf\" given the concept \"tree\"\n",
    "meronyms = wn.synsets(word)[0].part_meronyms()\n",
    "\n",
    "# Holonyms: opposite of meronyms - the concept to which a member is a part of, e.g. \"tree\" given the member \"leaf\"\n",
    "holonyms = wn.synsets(word)[0].member_holonyms()\n",
    "\n",
    "print(\"Hyponyms:\", hyponyms)\n",
    "print(\"Hypernyms:\", hypernyms)\n",
    "print(\"Meronyms:\", meronyms)\n",
    "print(\"Holonyms:\", holonyms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Exercise - A sentiment classifier\n",
    "- A rule-based approach with SentiWordNet + A machine learning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. There are several steps required to build a classifier or any sort of machine learning application for textual data. For data including (INPUT_TEXT, LABEL), list the typical pipeline for classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select relevant data: each piece of text (INPUT_TEXT) is associated with a label (LABEL), to ensure that the data is relevant and that the classes are clearly defined.\n",
    "\n",
    "2. Preprocessing: cleaning the data (e.g. removing noise, correcting spelling errors) and preparing it for further processing (e.g., tokenization, normalization, stemming, lemmatization).\n",
    "\n",
    "3. Splitting the data: dividing the dataset into a training set and a test set. The training set is used to train the machine learning model, while the test set is used to evaluate the model's performance.\n",
    "\n",
    "4. Feature extraction: features are extracted from the preprocessed text, using methods like Bag of Words, TF-IDF, or word embeddings.\n",
    "\n",
    "5. Training the classifier: train the selected classifier on the training set.\n",
    "\n",
    "6. Evaluating the model: evaluate the performance of the model based on how accurately it can classify the unseen data in the test set, using metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "7. Iterate and refine: potentially improve the model based on the evaluation, e.g. by selecting a different set of features, trying a different classification algorithm, or tuning the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Before developing a classifier, having a baseline is very useful. Build a baseline model for sentiment classification using SentiWordNet.**\n",
    "- How you decide to aggregate sentiment is up to you. Explain your approach.\n",
    "- It should report the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "sents = [\n",
    "    \"I liked it! Did you?\",\n",
    "    \"It's not bad but... Nevermind, it is.\",\n",
    "    \"It's awful\",\n",
    "    \"I don't care if you loved it - it was terrible!\",\n",
    "    \"I don't care if you hated it, I think it was awesome\"\n",
    "]\n",
    "\n",
    "# This method assumes that the sentiment of a text can be approximated by the cumulative sentiment of its constituent words.\n",
    "\n",
    "# convert spaCy POS tags to WordNet POS tags since SentiWordNet requires WordNet-specific POS tags.\n",
    "def convert_tags(pos_tag):\n",
    "    if pos_tag.startswith(\"ADJ\"):\n",
    "        return wn.ADJ\n",
    "    elif pos_tag.startswith(\"NOUN\"):\n",
    "        return wn.NOUN\n",
    "    elif pos_tag.startswith(\"ADV\"):\n",
    "        return wn.ADV\n",
    "    elif pos_tag.startswith(\"VERB\"):\n",
    "        return wn.VERB\n",
    "    return None  # For unhandled cases\n",
    "\n",
    "# get sentiment of a text using SentiWordNet\n",
    "def get_sentiment(text):\n",
    "    # preprocess the text using spaCy, which automatically tokenizes and assigns POS-tags\n",
    "    doc = nlp(text)\n",
    "    score = 0\n",
    "    for token in doc:\n",
    "        wn_tag = convert_tags(token.pos_)\n",
    "        if wn_tag not in (wn.ADJ, wn.ADV, wn.NOUN, wn.VERB):\n",
    "            continue  # skip irrelevant words\n",
    "\n",
    "        # calculate the sentiment score for each word and calculate the overall sentiment score for the text based on the sum of the averaged sentiment scores.\n",
    "        synsets = list(swn.senti_synsets(token.lemma_, pos=wn_tag))\n",
    "        if synsets:\n",
    "            # average the positive and negative sentiment scores synsets\n",
    "            for synset in synsets:\n",
    "                score += synset.pos_score() - synset.neg_score()\n",
    "    \n",
    "    # if the sum is positive, the text is classified as positive (1), otherwise, it's classified as negative (0). \n",
    "    return 1 if score > 0 else 0\n",
    "\n",
    "# truth labels\n",
    "y_true = [1, 0, 0, 0, 1]\n",
    "\n",
    "# predicted labels\n",
    "y_pred = [get_sentiment(sent) for sent in sents]\n",
    "\n",
    "# evaluate accuracy based on the proportion of correctly predicted sentiments in relation to the total number of sentences\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    accuracy = sum(1 for true, pred in zip(y_true, y_pred) if true == pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "print(\"Accuracy:\", get_accuracy(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SST-2 binary sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Split the training set into a training and test set. Choose a split size, and justify your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    5539\n",
      "0    4461\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62435</th>\n",
       "      <td>succeeded in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>figures prominently in this movie , and helps ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45783</th>\n",
       "      <td>with an unusual protagonist ( a kilt-wearing j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50278</th>\n",
       "      <td>give a spark to `` chasing amy '' and `` chang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45351</th>\n",
       "      <td>what 's most refreshing about real women have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "62435                                      succeeded in       1\n",
       "32549  figures prominently in this movie , and helps ...      1\n",
       "45783  with an unusual protagonist ( a kilt-wearing j...      1\n",
       "50278  give a spark to `` chasing amy '' and `` chang...      0\n",
       "45351  what 's most refreshing about real women have ...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "df = dataset[\"train\"].to_pandas().drop(columns=[\"idx\"])\n",
    "df_sample = df.sample(10000)  # a tiny subset\n",
    "print(df_sample.label.value_counts())\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting the dataset into training and test sets with an 80/20 split, to train the model on a substantial portion of the data while reserving enough unseen examples to evaluate its performance on data it hasn't seen before (as shown in Kochmar, ch. 2)\n",
    "\n",
    "# using seed 42 to make sure that all future runs will shuffle the data in the same way (Kochmar, ch. 2)\n",
    "train_data, test_data = train_test_split(df_sample, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluate your baseline model on the test set.**\n",
    "\n",
    "- Additionally: compare it against a random baseline. That is, a random guess for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (baseline model): 0.6765\n",
      "Accuracy (random baseline): 0.5120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict using the baseline model\n",
    "y_test_pred = [get_sentiment(sent) for sent in test_data['sentence']]\n",
    "\n",
    "# calculate accuracy of the baseline model\n",
    "baseline_accuracy = get_accuracy(test_data['label'], y_test_pred)\n",
    "print(f\"Accuracy (baseline model): {baseline_accuracy:.4f}\")\n",
    "\n",
    "# generate random predictions\n",
    "class_distribution = train_data['label'].value_counts(normalize=True)\n",
    "random_predictions = np.random.choice([0, 1], size=len(test_data), p=[class_distribution[0], class_distribution[1]])\n",
    "\n",
    "# calculate accuracy for the random predictions\n",
    "random_accuracy = get_accuracy(test_data['label'], random_predictions)\n",
    "print(f\"Accuracy (random baseline): {random_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Did you beat random guess?**\n",
    "\n",
    "If not, can you think of any reasons why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the baseline model beat the random guess, which indicates that the model is able to predict sentiments more accurately than an approach which make predictions randomly based on the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Naive Bayes and TF-IDF\n",
    "This is the final task of the lab. You will use high-level libraries to implement a TF-IDF vectorizer and train your data using a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78       903\n",
      "           1       0.79      0.92      0.85      1097\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.83      0.81      0.82      2000\n",
      "weighted avg       0.83      0.82      0.82      2000\n",
      "\n",
      "Accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# source: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#exercise-2-sentiment-analysis-on-movie-reviews\n",
    "\n",
    "# using sckit pipeline for TF-IDF vectorization and Naive Bayes classification as explained in the soure\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# training the classifier on the SST-2 data\n",
    "text_clf.fit(train_data['sentence'], train_data['label'])\n",
    "\n",
    "# predict test dataset labels\n",
    "predicted = text_clf.predict(test_data['sentence'])\n",
    "\n",
    "# evaluate the classifier\n",
    "# formatting with sckit classification report\n",
    "print(classification_report(test_data['label'], predicted))\n",
    "print(\"Accuracy:\", accuracy_score(test_data['label'], predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is just one out of infinitely many ways to approach this problem.\n",
    "Consider this: in lab 2 you explored word embeddings. In the playground file, there is an example of how we can project these word embeddings in a 2D space - and suddenly, text becomes any regular data points! Can you think of a way to use these word embeddings for classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings can be used in classification by converting the semantic meanings of words into vector representations. A fixed-length feature vector can then be created for each text, which can be fed into classifiers, e.g. SVM, to classify texts based on its semantic content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional task: using a pre-trained transformer model\n",
    "If you wish to push the accuracy as far as you can, take a look at BERT-based or other pre-trained language models. As a starting point, take a look at a model already fine-tuned on the SST-2 dataset: [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "\n",
    "**Advanced:**\n",
    "\n",
    "Going beyond this, you could look into the addition of a *classification head* on top of the pooling layer of a BERT-based model. This is a common approach to fine-tuning these models on classification or regression problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
